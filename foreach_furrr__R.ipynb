{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up your environment\n",
    "\n",
    "- The following example will work in your R Studio session with the packages indicated.  \n",
    "\n",
    "- In case you want to follow along in Jupyter:\n",
    "\n",
    "    Provided you have Jupyter installed (if not, you can download Anaconda), please follow the instructions at- https://irkernel.github.io/installation/  \n",
    "\n",
    "    Then on the conda prompt run:\n",
    "    \n",
    "    <code>jupyter-notebook</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pacman available"
     ]
    }
   ],
   "source": [
    "# Loading required libraries\n",
    "\n",
    "# Below I may explicitly call functions to indicate where they're from where there may arise ambiguity\n",
    "\n",
    "success <- suppressWarnings(sapply(c('pacman'), require, character.only = TRUE))\n",
    "if (length(names(success)[!success]) == 0) cat('pacman available') else install.packages(names(success)[!success])\n",
    "\n",
    "pacman::p_load(foreach, doParallel, future, rsample, dplyr)\n",
    "pacman::p_load_gh(c(\"DavisVaughan/furrr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does high performance computing involve?\n",
    "\n",
    "Particularly for the R ecosystem, you can find a list of packages and resources here- https://cran.r-project.org/web/views/HighPerformanceComputing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of doParallel and foreach\n",
    "\n",
    "Our first example will use these two packages. On Windows we stick to <code>makeCluster</code> instead of <code>makeForkCluster</code> from the <code>parallel</code> package. If you're not on windows <code>mclapply</code> also uses forking to allow lapply functionality parallelly.\n",
    "\n",
    "Alternatives to <code>doParallel</code> are <code>doMPI</code>, <code>doSNOW</code>, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Register a parallel backend\n",
    "\n",
    "cl <- makeCluster(parallel:::detectCores() - 1) # one fewer than what's available for safety\n",
    "registerDoParallel(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Riemann integration example from *Advanced R*\n",
    "\n",
    "https://en.wikipedia.org/wiki/Newton%E2%80%93Cotes_formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2.00000019739214"
      ],
      "text/latex": [
       "2.00000019739214"
      ],
      "text/markdown": [
       "2.00000019739214"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.95786642507409"
      ],
      "text/latex": [
       "1.95786642507409"
      ],
      "text/markdown": [
       "1.95786642507409"
      ],
      "text/plain": [
       "[1] 1.957866"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newton_cotes <- function(coef, open = FALSE) {\n",
    "  n <- length(coef) + open\n",
    "\n",
    "  function(f, a, b) {\n",
    "    pos <- function(i) a + i * (b - a) / n\n",
    "    points <- pos(seq.int(0, length(coef) - 1))\n",
    "\n",
    "    (b - a) / sum(coef) * sum(f(points) * coef)\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "monte_carlo <- function(f, a, b, n) {\n",
    "    x <- runif(n, a, b)\n",
    "    y <- (f(x)) / (1 / (b - a))\n",
    "    integral <- sum(y)/n\n",
    "    \n",
    "    integral\n",
    "}    \n",
    "\n",
    "    \n",
    "composite <- function(f, a, b, n, rule) {\n",
    "  if (deparse(substitute(rule)) != 'monte_carlo') {\n",
    "      points <- seq(a, b, length = n + 1)\n",
    "\n",
    "      area <- 0\n",
    "      for (i in seq_len(n)) {\n",
    "        area <- area + rule(f, points[i], points[i + 1])\n",
    "      }\n",
    "\n",
    "      area\n",
    "  } else {\n",
    "      monte_carlo(f, a, b, n)\n",
    "  }\n",
    "}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "boole <- newton_cotes(c(7, 32, 12, 32, 7))\n",
    "composite(sin, 0, pi, n = 1000, rule = boole)\n",
    "\n",
    "composite(sin, 0, pi, n = 1000, rule = monte_carlo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lessons\n",
    "\n",
    "- A functional idiom helps us avoid passing around data to workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>trapezoid</dt>\n",
       "\t\t<dd>1.99999999995888</dd>\n",
       "\t<dt>simpson</dt>\n",
       "\t\t<dd>2.00000000001826</dd>\n",
       "\t<dt>simpson2</dt>\n",
       "\t\t<dd>2.00000000002057</dd>\n",
       "\t<dt>boole</dt>\n",
       "\t\t<dd>2.00000000001972</dd>\n",
       "\t<dt>midpoint</dt>\n",
       "\t\t<dd>1.99999999995888</dd>\n",
       "\t<dt>milne</dt>\n",
       "\t\t<dd>1.99999999995888</dd>\n",
       "\t<dt>willm</dt>\n",
       "\t\t<dd>1.99999999996184</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[trapezoid] 1.99999999995888\n",
       "\\item[simpson] 2.00000000001826\n",
       "\\item[simpson2] 2.00000000002057\n",
       "\\item[boole] 2.00000000001972\n",
       "\\item[midpoint] 1.99999999995888\n",
       "\\item[milne] 1.99999999995888\n",
       "\\item[willm] 1.99999999996184\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "trapezoid\n",
       ":   1.99999999995888simpson\n",
       ":   2.00000000001826simpson2\n",
       ":   2.00000000002057boole\n",
       ":   2.00000000001972midpoint\n",
       ":   1.99999999995888milne\n",
       ":   1.99999999995888willm\n",
       ":   1.99999999996184\n",
       "\n"
      ],
      "text/plain": [
       "trapezoid   simpson  simpson2     boole  midpoint     milne     willm \n",
       "        2         2         2         2         2         2         2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.99999999998529"
      ],
      "text/latex": [
       "1.99999999998529"
      ],
      "text/markdown": [
       "1.99999999998529"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paramlist <- list(trapezoid = c(1, 1), simpson = c(1, 4, 1), simpson2 = c(1, 3, 3, 1), boole = c(7, 32, 12, 32, 7),\n",
    "                  midpoint = c(c(1), open = TRUE), milne = c(c(2, -1, 2), open = TRUE),\n",
    "                  willm = c(c(11, 1, 1, 11), open = TRUE))\n",
    "\n",
    "integrals <- foreach (i = seq_along(paramlist), .combine = c) %do% {\n",
    "    newton_cotes_rule <- newton_cotes(paramlist[[i]])\n",
    "    value <- setNames(composite(sin, 0, pi, n = 100000, rule = newton_cotes_rule), names(paramlist)[i])\n",
    "}\n",
    "\n",
    "integrals\n",
    "mean(integrals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Yes</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>No</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Yes</th><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & Yes\\\\\n",
       "\\hline\n",
       "\tNo & 0\\\\\n",
       "\tYes & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Yes | \n",
       "|---|---|\n",
       "| No | 0 | \n",
       "| Yes | 1 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    Yes\n",
       "No  0  \n",
       "Yes 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Attrition ~ JobSatisfaction + Gender + MonthlyIncome + \n",
       "    YearsSinceLastPromotion, family = binomial, data = trainset)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-0.9795  -0.6528  -0.5432  -0.3361   2.8184  \n",
       "\n",
       "Coefficients:\n",
       "                          Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)             -9.814e-01  1.874e-01  -5.237 1.63e-07 ***\n",
       "JobSatisfaction.L       -6.356e-01  1.661e-01  -3.826  0.00013 ***\n",
       "JobSatisfaction.Q        1.002e-01  1.699e-01   0.590  0.55545    \n",
       "JobSatisfaction.C       -2.066e-01  1.733e-01  -1.192  0.23312    \n",
       "GenderMale               1.151e-01  1.727e-01   0.666  0.50519    \n",
       "MonthlyIncome           -1.367e-04  2.682e-05  -5.098 3.43e-07 ***\n",
       "YearsSinceLastPromotion  2.736e-02  2.949e-02   0.928  0.35353    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 977.87  on 1101  degrees of freedom\n",
       "Residual deviance: 925.61  on 1095  degrees of freedom\n",
       "AIC: 939.61\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "           \n",
       "predictions  No Yes\n",
       "         No 310  58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data('attrition')\n",
    "contrasts(attrition$Attrition)\n",
    "\n",
    "p <- 3/4\n",
    "indices <- sample(nrow(attrition), size = floor((nrow(attrition) * p)))  \n",
    "trainset <- attrition[indices,]\n",
    "testset <- attrition[-indices,]\n",
    "\n",
    "lm_fit <- glm(Attrition ~ JobSatisfaction + Gender + MonthlyIncome + YearsSinceLastPromotion,\n",
    "              data = trainset, family = binomial)\n",
    "summary(lm_fit)\n",
    "\n",
    "probabilities <- predict(lm_fit, testset, type = 'response')\n",
    "predictions <- rep('No', dim(testset)[1])\n",
    "predictions[probabilities > 1/2] <- 'Yes'\n",
    "table(predictions, testset[['Attrition']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>elapsed:</strong> 23.8199999999924"
      ],
      "text/latex": [
       "\\textbf{elapsed:} 23.8199999999924"
      ],
      "text/markdown": [
       "**elapsed:** 23.8199999999924"
      ],
      "text/plain": [
       "elapsed \n",
       "  23.82 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# helper function for mode\n",
    "modefun <- function(x) {\n",
    "  ux <- unique(x)\n",
    "  ux[which.max(tabulate(match(x, ux)))]\n",
    "}\n",
    "\n",
    "\n",
    "bagged_lm_fit <- function(dataset, trainset, testset, quotient = 4, iterations = 10000) {\n",
    "    \n",
    "    predictions <- foreach(m=1:iterations, .combine=cbind) %dopar% {\n",
    "        train_indices <- sample(nrow(trainset), size = floor((nrow(trainset) / quotient)))\n",
    "        \n",
    "        lm_fit <- glm(Attrition ~ JobSatisfaction + Gender + MonthlyIncome + YearsSinceLastPromotion,\n",
    "                     data = dataset[(1:nrow(trainset) %in% train_indices),], family = binomial)\n",
    "        \n",
    "        probabilities <- predict(lm_fit, newdata = testset, type = 'response')\n",
    "        predictions <- rep('No', dim(testset)[1])\n",
    "        predictions[probabilities > 1/2] <- 'Yes'\n",
    "        predictions\n",
    "        }\n",
    "    \n",
    "    apply(predictions, 1, modefun)\n",
    "\n",
    "}\n",
    "\n",
    "# Let's compare dopar vs do:\n",
    "starttime <- proc.time()\n",
    "# You can also use the microbenchmark package or tictoc\n",
    "\n",
    "results <- bagged_lm_fit(attrition, trainset, testset)\n",
    "\n",
    "duration <- (endtime <- proc.time())[3] - starttime[3]\n",
    "duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redo with furrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To get you started:\n",
    "\n",
    "plan(multiprocess)\n",
    "\n",
    "quotient <- 4\n",
    "iterations <- 1:1000\n",
    "\n",
    "indices <- purrr::map(iterations, ~sample(nrow(trainset), size = floor((nrow(trainset) / quotient))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remember to stop your cluster once done.\n",
    "\n",
    "stopCluster(cl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
